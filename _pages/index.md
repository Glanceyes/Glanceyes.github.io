---
title: Seonho (Griffin Sunho) Lee
subtitle: M.S. Student at CVML Lab, KAIST AI
description: Research on AI especially in Computer vision and Computer Graphics
featured_image: /images/about/banner_image.jpg
---

# Hello

![Profile Image](/images/about/profile_image.jpg){: width="200" height="200" style="float: right; margin-right: 20px; margin-left: 20px; margin-bottom: 20px;"}

I am Seonho Lee (Griffin Sunho Lee in the US). I will be working as an AI Applied Scientist at Krafton AI starting in March 2026. I got a M.S. degree from [KAIST AI](https://gsai.kaist.ac.kr/) in Artificial Intelligence and had worked as an AI graduate researcher at the [Computer Vision and Machine Learning Lab](https://sites.google.com/view/cvml-kaist/home) at [KAIST](https://www.kaist.ac.kr/en/), under the supervision of [Prof. Hyunjung Shim](https://sites.google.com/view/cvml-kaist/members). 

<br/>

I am interested in research on AI especially in Computer vision. I hope to use AI to help people freely envision, realize, and share what they believe in.

<br/>

Particularly, I am researching on the following topics:

**1. Generative AI**

**2. Vision-Language Understanding**




<br/>

<a href="/pdf/cv.pdf" target="_blank" class="button button--medium"><i class="fa fa-file-pdf"></i> CV</a>
<a href="mailto:glanceyes@gmail.com" class="button button--medium"><i class="fa fa-envelope"></i> E-mail</a>
<a href="https://github.com/glanceyes" target="_blank" class="button button--medium"><i class="fa-brands fa-github"></i> Github</a>
<a href="https://www.linkedin.com/in/glanceyes" target="_blank" class="button button--medium"><i class="fa-brands fa-linkedin"></i> LinkedIn</a>
<a href="https://scholar.google.com/citations?user=DFKGTG0AAAAJ" target="_blank" class="button button--medium"><i class="fa-brands fa-google"></i> Google Scholar</a>
<br/>

- Email: glanceyes (at) kaist (dot) com

<br/>
<hr/>

## News

**Oct. 2025**: Two papers <b>[PartCATSeg](http://arxiv.org/abs/2501.09688)</b> and <b>[3D-Aware VLM Finetuning](http://arxiv.org/abs/2506.09883)</b> got selected as <b>[QIFK(Qualcomm Innovation Fellowship Korea) 2025](https://www.qualcomm.com/research/university-relations/innovation-fellowship/2025-south-korea) Finalist</b>.

**Aug. 2025**: Our <b>[3D-Aware VLM Finetuning](http://arxiv.org/abs/2506.09883)</b> paper got accepted to <b>[EMNLP 2025 Findings](https://2025.emnlp.org/)!</b>

**Jun. 2025**: I got ML engineering internship at [Snap Inc.](https://www.snap.com) in Santa Monica, CA.

**Jun. 2025**: I got awarded <b>[Korean Presidential Science Scholarship for Graduate Students](https://www.msit.go.kr/bbs/view.do?sCode=user&mPid=121&mId=311&bbsSeqNo=100&nttSeqNo=3179541)</b>.

**May. 2025**: Our <b>[ScribbleDiff](https://arxiv.org/abs/2409.08026)</b> paper got accepted to <b>[ICIP 2025](https://2025.ieeeicip.org/)!</b>

**Feb. 2025**: Our <b>[PartCATSeg](http://arxiv.org/abs/2501.09688)</b> paper got accepted to <b>[CVPR 2025](https://cvpr.thecvf.com/Conferences/2025)!</b>

**Jan. 2025**: Our <b>[DreamCatalyst](https://arxiv.org/abs/2407.11394)</b> paper got accepted to <b>[ICLR 2025](https://iclr.cc/Conferences/2025)!</b>

**Sep. 2024**: Our <b>[PartCLIPSeg](https://arxiv.org/abs/2406.11384)</b> paper got accepted to <b>[NeurIPS 2024](https://neurips.cc/Conferences/2024)!</b>

**Sep. 2023**: I got accepted to [CVML Lab](https://sites.google.com/view/cvml-kaist/home) as a M.S. graduate student in KAIST AI.

<br/>
<hr/>



## Publications

<br clear="all"/>
<b>*: equal contribution.</b> &nbsp; <b>†: corresponding author.</b> &nbsp; <b>C: conference</b> &nbsp; <b>P: preprint</b>

<br clear="all"/>

#### [C5] 3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation

![3D-Aware-VLM](/images/about/publications/3d_aware_vlm.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 60px; margin-bottom: 60px;"}

- <b>Seonho Lee</b>\*, Jiho Choi\*, Inha Kang, Jiwook Kim, Junsung Park, Hyunjung Shim†
- Keywords: 3D-Aware VLM Finetuning
<!-- - <i>May. 2025</i> -->

<b>[EMNLP 2025 Findings](https://2025.emnlp.org/)</b>, [Paper](http://arxiv.org/abs/2506.09883), [Codes](https://github.com/kaist-cvml/3d-vlm-gd)

<br clear="all"/>


#### [C4] Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation

![PartCATSeg](/images/about/publications/partcatseg.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 40px; margin-bottom: 40px;"}

- Jiho Choi\*, <b>Seonho Lee</b>\*, Seungho Lee, Minhyun Lee, Hyunjung Shim†
- Keywords: Open-Vocabulary Part Segmentation
<!-- - <i>Nov. 2024</i> -->

<b>[CVPR 2025](https://cvpr.thecvf.com/Conferences/2025)</b>, [Paper](http://arxiv.org/abs/2501.09688), [Codes](https://github.com/kaist-cvml/part-catseg)

<br clear="all"/>

#### [C3] Scribble-Guided Diffusion for Training-free Text-to-Image Generation

![Scribble-Guided Diffusion](/images/about/publications/scribblediff.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 20px; margin-bottom: 20px;"}

- <b>Seonho Lee</b>\*, Jiho Choi\*, Seohyun Lim, Jiwook Kim, Hyunjung Shim†
- Keywords: Conditional Image Generation
<!-- - <i>Sep. 2024</i> -->

<b>[ICIP 2025](https://2025.ieeeicip.org)</b>, [Paper](https://arxiv.org/abs/2409.08026), [Codes](https://github.com/kaist-cvml-lab/scribble-diffusion)

<br clear="all"/>

#### [C2] DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation

![DreamCatalyst](/images/about/publications/dreamcatalyst.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 20px; margin-bottom: 20px;"}

- Jiwook Kim\*, <b>Seonho Lee</b>\*, Jaeyo Shin, Jiho Choi, Hyunjung Shim†
- Keywords: 3D Editing, Score Distillation
<!-- - <i>Jul. 2024</i> -->

<b>[ICLR 2025](https://openreview.net/forum?id=FA5ZAJlv96)</b>, [Paper](https://arxiv.org/abs/2407.11394), [Project Page](https://dream-catalyst.github.io/), [Codes](https://github.com/kaist-cvml-lab/DreamCatalyst)

<br clear="all"/>

#### [C1] Understanding Multi-Granularity for Open-Vocabulary Part Segmentation

![PartCLIPSeg](/images/about/publications/partclipseg.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 40px; margin-bottom: 40px;"}

- Jiho Choi\*, <b>Seonho Lee</b>\*, Seungho Lee, Minhyun Lee, Hyunjung Shim†
- Keywords: Open-Vocabulary Part Segmentation
<!-- - <i>May. 2024</i> -->

<b>[NeurIPS 2024](https://neurips.cc/virtual/2024/poster/94085)</b>, [Paper](https://arxiv.org/abs/2406.11384), [Codes](https://github.com/kaist-cvml-lab/part-clipseg)

<br clear="all"/>


#### [P3] Mitigating Perceptual Judgment Bias in Multimodal LLM-as-a-Judge via Perceptual Perturbation and Reward Modeling

![Perceptual_Judge](/images/about/publications/perceptual_judge.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 60px; margin-bottom: 60px;"}

- Seojeong Park\*, Jiho Choi\*, Junyong Kang, <b>Seonho Lee</b>, Jaeyo Shin, Hyunjung Shim†
- Keywords: Multimodal LLM, Perceptual Judgment Bias
<!-- - <i>Nov. 2025</i> -->

Under Review

<br clear="all">

#### [P2] WaymoQA: A Multi-View Visual Question Answering Dataset for Safety-Critical Reasoning in Autonomous Driving

![WaymoQA](/images/about/publications/waymoqa.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 60px; margin-bottom: 60px;"}

- Seungjun Yu, <b>Seonho Lee</b>, Namho Kim, Jaeyo Shin, Junsung Park, Wonjeong Ryu, Raehyuk Jung, Hyunjung Shim†
- Keywords: Visual Question Answering, Safety-Critical Reasoning
<!-- - <i>Nov. 2025</i> -->

[Preprint](https://arxiv.org/abs/2511.20022)

<br clear="all"/>

#### [P1] What “Not” to Detect: Improving Object Detection under Negation via Reasoning and Token Merging

![CoVAND](/images/about/publications/covand.png){: width="20%" style="float: left; margin-right: 40px; margin-top: 60px; margin-bottom: 60px;"}

- Inha Kang, Youngsun Lim, <b>Seonho Lee</b>, Jiho Choi, Junsuk Choi†, Hyunjung Shim†
- Keywords: Described Object Detction under Negation
<!-- - <i>May. 2025</i> -->

[Preprint](https://arxiv.org/abs/2510.13232)


<br clear="all"/>



<br/>
<hr/>


## Work Experience

#### Snap Inc.

- ML engineer intern at Generative ML team (VideoCraft)
- <i>Jun. 2025 ~ Sep. 2025</i>, Santa Monica, CA, USA (On-site)
- Led a project for establishing cross-reference dataset preprocessing pipeline for personalized video generation
- Developed new model architecture with multi-subject adapters for <i>VideoAlchemist 2.0</i>

<br/>

<!-- #### Life Planning Lab
- Data engineer & Back-end engineer
- <i>Dec. 2021 ~ Jan. 2022</i>, Seoul
- Developed back-end platform and data preprocessor


<br/> -->
<hr/>


## Projects

#### 3D-Aware VLM Finetuning, Samsung Research
- Electronic Device and Method for Operating Thereof and Storage Medium
- Korean patent: 10-2025-0109574

<br/>

#### SHrack: Mobile Web Service for Real-time Exercise Count Tracking
- Web-based real-time video streaming service for accurate exercise count detection
- Keywords: MobileNet, Contextual Prediction Module

[Review](https://glanceyes.github.io/project/shrack)

<br/>

#### RECJOON: Backjoon Online Judge Problem Solving Recommendation System

- Naver Boostcamp AI Tech 3rd <i>(Mar. 2022 ~ Jun. 2022)</i>
- Keywords: Recommendation System

[Review](https://glanceyes.github.io/project/recjoon), [Codes](https://github.com/boostcampaitech3/final-project-level3-recsys-14)

<br/>

#### KUVIS: Web-based Visual Programming Software with Deep Learning in Medicine

- Seonho Lee, Yoomin Kang, Advised by Prof. Wonki Jeong <i>(Jul. 2022 ~ Aug. 2022)</i>
- Keywords: Visual Programming, Parallel Computing for Deep Learning
- Prototype of [VIENCE Pathoview](https://vience.io/main)

[Review](https://glanceyes.github.io/project/kuvis), [Projects](/project/kuvis)


<br/>
<hr/>

## Education

#### KAIST
- M.S. in Artificial Intelligence, Mar. 2024 ~ Feb. 2026 <i>(Expected)</i>
- GPA: 4.20 / 4.3

#### Sogang University
- B.S. in Computer Science and Engineering, Mar. 2017 ~ Feb. 2024 <i>(Expected)</i>
- GPA: 4.12 / 4.3 <i>(Summa Cum Laude)</i>

#### Sangsan High School


<br/>
<hr/>


## Honors and Awards

#### Qualcomm Innovation Fellowship Korea (QIFK) 2025 Finalist
- Selected as a finalist by Qualcomm AI Research <i>(Oct. 2025)</i>
- Two papers: [PartCATSeg](http://arxiv.org/abs/2501.09688) and [3D-Aware VLM Finetuning](http://arxiv.org/abs/2506.09883)

#### Korean Presidential Science Scholarship for Graduate Students
- Awarded by the President of Korea <i>(Jun. 2025)</i>

#### 2nd Place on Open Vocabulary Part Segmentation Challenge at CVPR 2024
- 2nd Place Winnder both on Track 1 and 2
- 4th workshop on Open World Vision at CVPR 2024

#### Excellence Award in 2023 POSTECH OIBC Challenge
- 3rd Place (3/120) in AI Competition of Solar Power Generation Forecasting <i>(Dec. 2023)</i>

#### 2022 ICPC Asia Korea Regional Contest
- 48th in Korea, 62nd in Preliminary

#### Korea National Science and Technology Scholarship
- Spring 2019, Fall 2022, Spring 2023, Fall 2023 <i>(4 Semesters)</i>

#### Dean's List, Sogang University
- 1%: Spring 2018, Spring 2019, Fall 2022
- 5%: Fall 2018

<br/>
<hr/>


## Academic Activities

#### Reviewer
- 3DV 2026


<br/>
<hr/>


<!-- 
## Extra-Curricular Activities

#### Naver Boostcamp AI Tech 3rd
- Participated in courses and competitions hosted by Upstage


<br/>
<hr/>



## Skills

#### Languages
- Python, SQL, C++, C, JavaScript, Bash, PHP

#### Libraries & Frameworks
- PyTorch, TensorFlow, Node.js, OpenGL, CUDA

#### Tools
- Git, Docker, Kubernetes, AWS, Google Cloud, Shell, MLflow

#### Algorithm & Problem Solving
- Profile Links (Korean Leetcode)
    + [Baekjoon Online Judge](https://www.acmicpc.net/user/glanceyes)
    + [Solved.ac](https://solved.ac/profile/glanceyes) 


<br/>
<hr/>
-->

```
Last updated: 4th, Jan. 2026
```
