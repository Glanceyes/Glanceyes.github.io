---
title: AudioToken&#58Text-to-Image Generation ëª¨ë¸ì„ ì‚¬ìš©í•œ Audio-to-Image Generation
date: '2023-09-16 01:30:00'
featured_image: https://vip2.loli.io/2023/09/16/hHsF1Lpt4UIXzqZ.png
published: true
---





> ## [AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation](https://arxiv.org/abs/2305.13050)

<br/>

## Overview



![AudioToken](https://vip2.loli.io/2023/09/16/hHsF1Lpt4UIXzqZ.png)



- Pre-trained text-to-image generation model (Stable Diffusion)
- Pre-trained audio-encoder ([BEATs](https://arxiv.org/abs/2212.09058))
- MLP + Attentive Pooling í•™ìŠµì‹œí‚´ (by conditional diffusion loss + classification loss)



<br/>



## Contribution



- Pre-trained text-conditioned generative modelì„ ì´ìš©í•´ì„œ audio-based conditioning êµ¬í˜„
- ì´ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ evaluation framework ì œì‹œ
  - Audio-Image Similarity, Image-Image Similarity, Audio-Image Content



<br/>



## Method



- 'BEATs'ë¼ëŠ” pre-trained audio classification networkë¥¼ ì‚¬ìš©

  - Earlier layers(4, 8, 12ë²ˆì§¸ ë ˆì´ì–´)ì™€ last hidden layerë¥¼ concatenation â†’ temporal audio embeddingìœ¼ë¡œ ì‚¬ìš©

- ì´ë¥¼ textual embedding spaceë¡œ projection í•˜ëŠ” MLPì™€ attentive pooling layer í•™ìŠµì‹œì¼œ í†µê³¼ë˜ì–´ ë‚˜ì˜¨ audio embeddingì„ 'a photo of a' tokenë“¤ ë’¤ì—ë‹¤ê°€ ë¶™ì„

  - ë‘ ê°œì˜ Linear layer + GELU non-linear activation function

    ![audiotoken_embedding1](https://vip2.loli.io/2023/09/16/U7V3OD9XYdKtnHM.png){: width="50%" height="50"}

    ![audiotoken_embedding2](https://vip2.loli.io/2023/09/16/zuQD5ZST6298qA4.png){: width="60%" height="50"}

- í•´ë‹¹ textë¥¼ text-encoderë¡œ CLIP embedding ìƒì„± í›„ ì´ë¥¼ T2I modelì˜ cross-attention layerì— injection

- Trainingì€ ì¼ë°˜ì ì¸ Conditioned diffusion modelì˜ loss + Classification loss

  ![audiotoken_loss1](https://vip2.loli.io/2023/09/16/GAgRJjVeB8xnUIt.png){: width="70%" height="50"}

  

  - ì¼ë°˜ì ì¸ Diffusion Modelì—ì„œì˜ Loss (ğœëŠ” conditioningì„ ìœ„í•œ encoder)

    ![audiotoken_loss2](https://vip2.loli.io/2023/09/16/JKZCghsxOIwEY89.png){: width="100%" height="50"}

  - audio embeddingê³¼ ë°ì´í„°ì˜ labelì˜ ìœ ì‚¬ë„ê°€ ë†’ì•„ì§€ë„ë¡ í•˜ëŠ” loss

    ![audiotoken_loss3](https://vip2.loli.io/2023/09/16/9FYzPHL6DhmO5gW.png){: width="50%" height="50"}

  - Pre-trained ëª¨ë¸ë“¤ì€ frozen ì‹œí‚¤ê³  ìƒˆë¡­ê²Œ ì¶”ê°€í•œ layerë“¤ë§Œ í•™ìŠµì‹œí‚´



<br/>



## Evaluation



- Audio-Image Similarity
  - Wav2CLIP ëª¨ë¸ ì‚¬ìš©
    - Audio-Image ê°„ì˜ ìœ ì‚¬ë„ ì¸¡ì • ê°€ëŠ¥
- Image-Image Similarity
  - ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ground truth ì´ë¯¸ì§€ ê°„ì˜ CLIP score ë¹„êµ
- Audio-Image Content
  - Image classifierì—ì„œ ì˜ˆì¸¡ëœ classì™€ ground truth audio label ê°„ì˜ additional CLIP-based score ì‚¬ìš©
- Human Evaluation
  - ì¼ë°˜ì ì¸ ìœ ì € í‰ê°€
  - ìƒì„±ëœ ì´ë¯¸ì§€ê°€ labelê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ 1ì—ì„œ 5ì  ì‚¬ì´ë¡œ í‰ê°€



<br/>





## Result

![audiotoken_result](https://vip2.loli.io/2023/09/16/iIFqfGbelWs7SEC.png)

- ìœ„ì—ì„œ ì•„ë˜ë¡œ Wav2Clip, Image-Bind, AudioToken, ê·¸ë¦¬ê³  Ground Truth

<br/>

![audiotoken_result2](https://vip2.loli.io/2023/09/16/kRMSJ6lBQtE1qpY.png)

<br/>



## Details



- Pre-trained text-to-image diffusion model(e.g. stable diffusion)ê³¼ pre-trained audio-encoderë¥¼ ì‚¬ìš©í•´ì„œ input audio signalì— ì˜ ë¶€í•©í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì
  - ì™œ audioë¥¼ textë¡œ mappingí•˜ëŠ” pre-trained encoder + auxiliary neural network(MLP)ë¥¼ ì‚¬ìš©í•´ì„œ êµ³ì´ audio signalì„ text space ìœ„ë¡œ projection ì‹œí‚¤ëŠ”ê°€?
    - Pre-trained text-to-image generation model ì‚¬ìš©í•˜ê¸° ìœ„í•´
      - â€œnot learn a new generative model with audio-visual pairsâ€
    - ë³´í†µ CLIPì„ ê°€ì§€ê³  ì‚¬ìš©í•œ ëª¨ë¸ì´ ë§ì€ë°, ë³„ë„ì˜ í•™ìŠµ ì—†ì´ ì´ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ audioë¥¼ text embeddingìœ¼ë¡œ ì˜ mapping ì‹œí‚¤ëŠ” ê²ƒì´ í•„ìš”
    - ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ í•µì‹¬ì€ ì„±ëŠ¥ì´ ì¢‹ì€ text-to-image generation modelì„ ì˜ leverage í•˜ìëŠ” ê²ƒ.



<br/>



## Takeaway Message



- Audio inputì— ê´€í•´ ë„ˆë¬´ ë‹¨ìˆœí•œ ì´ë¯¸ì§€ë§Œ ìƒì„±í•˜ì§€ ì•Šì„ê¹Œ?
  - 'ê°œê°€ ì§–ëŠ” ì†Œë¦¬' â†’ 'ê°œ ì´ë¯¸ì§€'
  - ë…¼ë¬¸ì˜ figureë¥¼ ë³´ë©´ ì •ë§ ë³µì¡í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ”ì§€ì— ê´€í•´ ì˜ë¬¸
    - Figure ìˆ˜ë„ ê·¸ë ‡ê²Œ ë§ì§€ ì•Šë‹¤.
- Audio-to-text encoderì˜ ì„±ëŠ¥ì— sensitive í•  ê²ƒ ê°™ë‹¤.
  - Stable Diffusion(SD)ë“± text-to-image ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ audio-to-image taskë¥¼ í•´ê²°í•˜ë ¤ëŠ” ì‹œë„ëŠ” ì¢‹ìœ¼ë‚˜, ê·¸ëŸ¬ë©´ text-to-image ìƒì„± ì„±ëŠ¥ì€ ì˜¤ë¡œì§€ stable diffusionì— bounded ë˜ë¯€ë¡œ chicken neck problemì´ì§€ ì•Šì„ê¹Œ ì‹¶ë‹¤.
  - ê·¸ë¦¬ê³  pre-trained audio encoderë¥¼ textual embedding spaceì— mappingí•˜ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ MLP í•™ìŠµ â†’ ì™„ì „í•œ training-free ë°©ì‹ì´ ì•„ë‹ˆë‹¤.
- Audioì— ê´€í•œ spatial informationë„ ê°™ì´ ë°˜ì˜í•˜ë©´ ì–´ë–¨ê¹Œ?
  - Stereoë¡œ ë…¹ìŒëœ ìŒì›ì— ê´€í•´ ìŒì›ì´ ë“¤ë ¤ì˜¤ëŠ” ë°©í–¥ì— ë”°ë¼ ì´ë¯¸ì§€ì—ì„œ ìƒì„±ë˜ëŠ” ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì¡°ì ˆí•˜ëŠ” ê²ƒ.
    - ê°œì¸ì ìœ¼ë¡œ ì—°êµ¬ ì¤‘ì¸ Stable Diffusionì—ì„œ ì›í•˜ëŠ” í¬ê¸°ì™€ ìœ„ì¹˜ë¡œ ê° ê°ì²´ë¥¼ positioning í•˜ë„ë¡ ìƒì„±í•˜ëŠ” guidance in diffusion modelì„ ë…¹ì—¬ë‚¼ ìˆ˜ ìˆì„ ë“¯.
    - ì›í•˜ëŠ” í¬ê¸°ì™€ ìœ„ì¹˜ì— ê°ì²´ë¥¼ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ë…¼ë¬¸ì€ ê½¤ ìˆë‹¤. â†’ ì´ë¥¼ audioì™€ ê²°í•©í•˜ë ¤ëŠ” ì‹œë„ëŠ” ì–´ë–¨ì§€ê°€ ê°œì¸ì ì¸ ì˜ê²¬.
      - e.g. ì™¼ìª½ì—ì„œ ì£¼ë¡œ ê°œêµ¬ë¦¬ ì†Œë¦¬ê°€ ë“¤ë¦¬ë©´ ì´ë¯¸ì§€ì—ì„œë„ ì™¼ìª½ ì˜ì—­ì— ê°œêµ¬ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒ.
    - Objectë¥¼ guidance í•˜ëŠ” ê²ƒì€ ì–´ë µì§€ ì•Šìœ¼ë‚˜, ê° ë°©í–¥ì—ì„œ ë“¤ë ¤ì˜¤ëŠ” ì†Œë¦¬ê°€ ì–´ë– í•œ ê°ì²´ì— í•´ë‹¹ë˜ëŠ” ì†Œë¦¬ì¸ì§€ë¥¼ êµ¬í•˜ëŠ” ê²Œ ì–´ë ¤ìš¸ ê²ƒ ê°™ë‹¤.
      - Textì—ì„œ subject tokenì„ ë½‘ê³ , ì´ë¥¼ ê° ë°©í–¥ì˜ ì†Œë¦¬ì™€ Hungarian algorithmìœ¼ë¡œ matching ì‹œí‚¤ëŠ” ë°©ë²•ì€?
      - Subject tokenê³¼ ì£¼ìš”í•œ audio signalì„ ì˜ matching í•˜ëŠ” ê²Œ ë‚œê´€ì´ ë  ë“¯.
    - ì´ë™í•˜ëŠ” ì†Œë¦¬(e.g. ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì°¨ ì†Œë¦¬ê°€ ì´ë™)ì— ê´€í•´ì„œëŠ” ì–´ë–»ê²Œ ì´ë¯¸ì§€ë¡œ ìƒì„±í•´ì•¼í• ì§€ ì˜ë¬¸
- T2I modelì„ fine-tuning ì‹œí‚¤ëŠ” ë°©ë²•ë“¤ì´ ë§ì´ ë‚˜ì™”ëŠ”ë° (e.g. ControlNet, GLIGEN ë“±) ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì„ ì´ìš©í•˜ë©´ ì–´ë–¨ê¹Œ?
  - Training ìì²´ê°€ costê°€ í¬ë‹¤.
  - ë¬¸ì œëŠ” audioì—ì„œ grounding tokenì„ ë½‘ì•„ë‚´ëŠ” ê²ƒ.



<br/>



## Reference



1. Guy Yariv et. al., "AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation", arXiv:2305.13050 (2023)
